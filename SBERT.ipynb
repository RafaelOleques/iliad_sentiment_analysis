{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6b843-df2e-42ca-925b-6282904ccd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17e02e-7b01-44d1-9798-ef969744c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a98125-4ea1-4013-8825-e674abbe706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566271c-8c2c-4122-a888-e465cb8cfe18",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488e3b9-8786-4e87-9419-5f87396c7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/iliad_sentiments.csv\"\n",
    "target = \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a01f5b-1358-4eec-99a8-5281af79e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    \"TF-IDF sem lematização\": {\"lemmatize\": False, \"sbert\": False},\n",
    "    \"TF-IDF com lematização\": {\"lemmatize\": True, \"sbert\": False},\n",
    "    \"SBERT com lematização\": {\"lemmatize\": False, \"sbert\": True},\n",
    "           }\n",
    "'''\n",
    "scenarios = {\n",
    "    \"TF-IDF sem lematização\": {\"lemmatize\": False, \"sbert\": False},\n",
    "    \"TF-IDF com lematização\": {\"lemmatize\": True, \"sbert\": False}\n",
    "           }\n",
    "'''\n",
    "classifiers = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(), \n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "STANDARD = \"Sem modificação\"\n",
    "WITHOUT_NARRATOR = \"Sem narrador\"\n",
    "MERGE_NARRATOR_NEUTRAL = \"Junção de narrador e neutro\"\n",
    "\n",
    "data_operations = [STANDARD, WITHOUT_NARRATOR, MERGE_NARRATOR_NEUTRAL]\n",
    "\n",
    "nro_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbd107-4c86-4bba-afd5-28b985c1e928",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f5ff6-4766-43a8-aa58-317edf04f520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcea7dc-efd9-4453-8918-d81860ccb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''metrics = {}\n",
    "\n",
    "for operation in data_operations:\n",
    "    metrics[operation] = {}\n",
    "\n",
    "for scenario in scenarios:\n",
    "    for operation in data_operations:\n",
    "        trainer = Trainer(path, target)\n",
    "        \n",
    "        if operation == STANDARD:\n",
    "            trainer.prepare_data_to_train(lemmatize=scenarios[scenario][\"lemmatize\"], sbert=scenarios[scenario][\"sbert\"])\n",
    "        if operation == WITHOUT_NARRATOR:\n",
    "            trainer.remove_class([\"narrator\"])\n",
    "            trainer.prepare_data_to_train(lemmatize=scenarios[scenario][\"lemmatize\"], sbert=scenarios[scenario][\"sbert\"])\n",
    "        elif operation == MERGE_NARRATOR_NEUTRAL:\n",
    "            trainer.merge_class([\"narrator\"], \"neutral\")\n",
    "            trainer.prepare_data_to_train(lemmatize=scenarios[scenario][\"lemmatize\"], sbert=scenarios[scenario][\"sbert\"])\n",
    "    \n",
    "        for classifier in classifiers:\n",
    "            metrics[operation][classifier] = {}\n",
    "\n",
    "        for classifier in classifiers:\n",
    "            metrics[operation][classifier][scenario] = trainer.cross_validation(model=classifiers[classifier], nro_folds=nro_folds)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7becdc-81e4-4e61-8f22-d5d20cc6cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "for classifier in classifiers:  \n",
    "    metrics[classifier] = {}\n",
    "        \n",
    "    for scenario in scenarios: \n",
    "        metrics[classifier][scenario] = {}\n",
    "\n",
    "for classifier in classifiers:       \n",
    "    for scenario in scenarios: \n",
    "        for operation in data_operations:\n",
    "            trainer = Trainer(path, target)\n",
    "\n",
    "            if operation == STANDARD:\n",
    "                trainer.prepare_data_to_train(lemmatize=scenarios[scenario][\"lemmatize\"], sbert=scenarios[scenario][\"sbert\"])\n",
    "            if operation == WITHOUT_NARRATOR:\n",
    "                trainer.remove_class([\"narrator\"])\n",
    "                trainer.prepare_data_to_train(lemmatize=scenarios[scenario][\"lemmatize\"], sbert=scenarios[scenario][\"sbert\"])\n",
    "            elif operation == MERGE_NARRATOR_NEUTRAL:\n",
    "                trainer.merge_class([\"narrator\"], \"neutral\")\n",
    "                trainer.prepare_data_to_train(lemmatize=scenarios[scenario][\"lemmatize\"], sbert=scenarios[scenario][\"sbert\"])\n",
    "                \n",
    "            metrics[classifier][scenario][operation] = trainer.cross_validation(model=classifiers[classifier], nro_folds=nro_folds)\n",
    "            print(f\"{classifier} : {scenario} : {operation}\")\n",
    "            print(metrics[classifier][scenario][operation])\n",
    "            print(\"=======================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2de93f-2370-4faf-8b39-949b962cb189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_boxplot(dict_metrics, labels, width=22, height=10):\n",
    "    plots = []\n",
    "    result = {}\n",
    "    \n",
    "    for model in dict_metrics:\n",
    "        result[model] = {}\n",
    "    \n",
    "    #plot\n",
    "    for model in dict_metrics:\n",
    "        #line\n",
    "        for scenario in dict_metrics[model]:\n",
    "            if scenario not in result[model]:\n",
    "                result[model][scenario] = {}\n",
    "            #Values\n",
    "            for data_operation in dict_metrics[model][scenario]:\n",
    "                for metric in dict_metrics[model][scenario][data_operation]:\n",
    "                    if metric not in result[model][scenario]:\n",
    "                        result[model][scenario][metric] = []\n",
    "                        result[model][scenario][metric].append(dict_metrics[model][scenario][data_operation][metric])\n",
    "                    else:\n",
    "                        result[model][scenario][metric].append(dict_metrics[model][scenario][data_operation][metric])\n",
    "    \n",
    "    for title in result:\n",
    "        number_type_trainers = len(result[title])\n",
    "\n",
    "        firts_key = list(result[title].keys())[0]\n",
    "        number_metrics = len(result[title][firts_key])\n",
    "\n",
    "        print(number_type_trainers, number_metrics)\n",
    "        \n",
    "        fig, ax = plt.subplots(number_type_trainers, number_metrics, figsize=(width, height))\n",
    "        print(ax.shape)\n",
    "        fig.suptitle(title)\n",
    "        print(title)\n",
    "\n",
    "        scenarios = result[title]\n",
    "\n",
    "        for idx_scenario, scenario in enumerate(scenarios):\n",
    "            metrics = scenarios[scenario]\n",
    "            for idx_metric, metric in enumerate(metrics):\n",
    "                results=[]\n",
    "\n",
    "                for values in metrics[metric]:\n",
    "                    results.append(values)\n",
    "\n",
    "                #ax[idx_scenario][idx_metric].set_ylim(bottom=0, top=100)\n",
    "                print(idx_scenario, idx_metric, results)\n",
    "                ax[idx_scenario][idx_metric].boxplot(results, labels=labels, showmeans=True)\n",
    "        \n",
    "                ax[idx_scenario][idx_metric].set_title(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1355b73-a7b5-419d-8ddb-b333380d615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_boxplot(metrics, data_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec30d2-2bd1-4481-83ac-490b4c0cd896",
   "metadata": {},
   "source": [
    "# Visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17df74-f186-4ca4-a2e6-a67267cf79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizations import compare_boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece79d8-fd3b-491c-bfe3-c93204a8ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_boxplot(metrics, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6592ba9-178a-4e59-8436-b4ee3dc9c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "compare_boxplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
